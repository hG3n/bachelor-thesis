Im Rahmen des Kapitels \enquote{Evaluation} wurden beide entwickelten Methoden in verschiedenen Versuchen getestet. Die erlangten Ergebnisse beider Algorithmen unterscheiden sich in diversen Bereichen. Es erfolg somit eine Gegenüberstellung beider Algorithmen in Hinsicht auf die Robustheit der Erkennung sowie deren Performance.

% generell ist zu sagen das die mean besser funktioniert wenn die hindernisse nicht vor einem weit entfernten hintergrund platziert werden

% durch die geringen disparitäten der hinteren 'ebene' wirrd der median so weit verzerrt, dass kleine objekte einfach nicht mehr auffallen

% wenn hintergrund höhere disparitäten aufweist fallen hohe disparitäten auch mehr ins gewicht

% zum teil auch so bei der samplepoint detection, jedoch erwies sich diese in den tests als robuster

% gerade kleine Hindernisse wurden auf distanz besser erkannt

% trotzallem nicht immer eindeutig teilweise wurde ein Teil des objektes erkannt wie der stab aber nicht das eigentlich gesuchte objekt

% 

% ---------------------- section -----------------------
\section{Gegenüberstellung beider Algorithmen}
\label{sec:gegenueberstellung}

\subsection{Performance}
\label{subsec:discussion_performance}

Hinsichtlich der Performance der entwickelten Systeme wurden verschiednen Punkte betrachtet. Die zugrunde liegende Berechnung der Disparity Map ist der wohl wichtigste Faktor. Ist dieser Prozess langsam, so ist auch die Performance der Hinderniserkennung eingeschränkt. Weiterhin wird auch die Performance der einzelnen Methoden untersucht. Dabei werden folgende Situationen untersucht:
\begin{enumerate}
	\item Analyse der gesamten Schleife des Hauptprogramms
	\begin{enumerate}
		\item Hindernisse bewegen sich durch die Gefahrenzone
		\item der gesamte Sichtbereich ist mit einem Hindernis gefüllt
		\item es befindet sich kein Hindernis in der Gefahrenzone
	\end{enumerate}
	\item Analyse einzelner Erkennungssschritte
	\begin{enumerate}
		\item Geschwindigkeit der Update Funktion
		\item Geschwindigkeit der detectObstacles Funktion ohne Hindernisse
		\item Geschwindigkeit der detectObstacles Funktion mit einem Hindernis im gesamten Sichtbereich
	\end{enumerate}
\end{enumerate}

\noindent
Zu Beginn ist ein essenzieller Schritt die Geschwindigkeit der Disparity Map Berechnung zu analysieren. Dabei wurden beide Kameras im gebinnten Modus getestet. Die Aufnahmerate der Kameras beträgt dabei 50 Frames pro Sekunde bei einer Verschlusszeit von 10000 µs. Die unter Veränderung der Blockgröße erhaltenen Parameter sind in Tabelle \ref{tbl:disparity_framerate} dargestellt. Aus dieser ist zu erkennen, dass eine Modifikation dieses Parameters nur marginale Änderungen in der Geschwindigkeit auftreten.

\begin{table}[h]
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	Block Größe & Zeit pro Frame & Frames pro Sekunde \\ \hline
	7           & 0.0412         & 24.21            \\ \hline
	9           & 0.0420         & 23.77            \\ \hline
	11          & 0.0413         & 24.17            \\ \hline
	13          & 0.0410         & 24.36            \\ \hline
	15          & 0.0412         & 24.22            \\ \hline
	21          & 0.0413         & 24.17            \\ \hline
	\end{tabular}
	\caption{Blockgröße und daraus resultierende Frameraten}
	\label{tbl:disparity_framerate}
\end{table}

\noindent
Die dabei gemessene Bildwiederholrate von 24 Einzelbildern pro Sekunde ist eine gute Voraussetzung für die Hinderniserkennung. Unter der Annahme das es zu keiner Verlangsamung dieser kommt ist es möglich sich mit Einer Geschwindigkeit von $12\frac{m}{s}$ zu bewegen und für jeden zurückgelegten Meter 2 berechnete Disparity Maps zu erhalten. Eine solche Geschwindigkeit ist bei besagter Framerate nicht die präferierte Geschwindigkeit jedoch potentiell möglich. Zudem in weiteren Schritten mehr Zeit für die Entwicklung einer Vermeidungsstrategie in Betracht gezogen werden muss.\\

\noindent
Die Geschwindigkeit der eigentlichen Hinderniserkennung ist ebenfalls ein wesentlicher Faktor in der Betrachtung der gesamten Performance. Dazu wurden besaget Tests durchgeführt. Die daraus erhaltenen Ergebnisse für die Subimage Detection finden sich in Tabelle \ref{tbl:subimage_framerate}.

%TODO FIX THIRD ROW 
\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
Szenario & Zeit pro Frame (Detection) & Detection fps \\ \hline\hline
1(a)     & 0.0057                     & 173.35        \\ \hline
1(b)     & 0.0067                     & 147.69        \\ \hline
1(c)     & 0.0067                     & 147.69        \\ \hline\hline
2(a)     & 0.0021                     & 469.93        \\ \hline
2(b)     & 0.0001                     & 8759.63       \\ \hline
2(c)     & 0.0042                     & 234.64        \\ \hline
\end{tabular}
\caption{Gemessene Einzelbilder pro Sekunde sowie Gesamtframerate}
\label{tbl:subimage_framerate}
\end{table}

\noindent
Aus dieser wird ersichtlich, dass Szenario 1(a), welches einer echten Anwendung am nächsten kommt, bereits eine Framerate von 173 Einzelbildern pro Sekunde aufweist. Die darauf folgendenTests bestätigen die Annahme, dass keine wesentlich langsamere Framerate aufgrund der Hinderniserkennung zu erwarten ist. Im schlechtesten Fall, einem Hindernis welches den gesamtem Sichtbereich einnimmt ist die kombinierte Framerate nicht geringer als XXX wie die folgende Rechnung aufzeigt. Dabei entsprechen die genutzten Werte denen aus \ref{tbl:disparity_framerate} mit 13 Pixeln Blockgröße sowie \ref{tbl:subimage_framerate} 1(b). 

\begin{equation}
\label{eq:fps_calculation}
\begin{aligned}
	fps &= \frac{1}{t_{frame}}\\
	t_{frame} &= 0.0410 + 0.0067 = 0.0477\\
	fps &= \frac{1}{0.0477} = 20,96
\end{aligned}
\end{equation}

\noindent


\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
Szenario & Zeit pro Frame (Detection) & Detection fps \\ \hline\hline
1(a)     & 0.0074           			  & 133.61         \\ \hline
1(b)     & 0.0100           			  & 99.33          \\ \hline
1(c)     & 0.0016           			  & 606.84         \\ \hline\hline
2(a)     & 0.0015           			  & 647.07         \\ \hline
2(b)     & 0.0015           		  	  & 647.07         \\ \hline
2(c)     & 0.0083           	 		  & 120.33         \\ \hline
\end{tabular}
\caption{Gemessene Einzelbilder pro Sekunde sowie Gesamtframerate}
\label{tbl:samplepoint_framerate}
\end{table}

% hinsichtlich performance verschiedene Punkte betrachtet
% erkennung pro frame im mittel
% framerate der Disparity berechnung
% gesamte framerate und ausblick auf die darurch erreichbare performance
% evtl auslagern und eigenne section machen da beide direkt gegenübergestllt werden können.
    
% resizing der initalbilder zur performance verbesserung

\subsection{Robustheit}
\label{subsec:discussion_robustness}
Wie die Evaluation bereits aufzeigt ist die Erkennung unterschiedlicher Hindernisgrößen als robust anzusehen. Beide Algorithmen erkennen sowohl große als auch kleine Hindernisse innerhalb der definierten Gefahrenzone. Die ermittelten Distanzen weisen zwar kleine Ungenauigkeiten auf, jedoch sind diese eher ein Resultat von Messungenauigkeiten sowie der verwendeten Bildgröße. Auch die dahingehend erstellten Punktwolken liefern genaue Positionsinformationen ausgehend von der aktuellen Weltposition der Drohne. Jene liegen im Rahmen dieser Arbeit nicht vor da dies als ein anderer Teil des SLAM Forschungsfeldes anzusehen ist.\\

% TODO Bilder pointcloud mean und sample desselben Objektes

\noindent
Bei der Erkennung kleiner Hindernisse ist jedoch zu erkennen, dass die entwickelte Samplepoint Detection wesentlich robustere Ergebnisse liefert als die Subimage Detection. Dies resultiert vornehmlich aus der signifikant kleineren Anzahl an Pixeln. Dadurch sind diese weniger empfänglich für Verzerrungen der berechneten Distanz wie Subimages. Enthält ein einziger Samplepoint zu wenige Daten um als Hindernis angesehen zu werden, so ist die Wahrscheinlichkeit das seine Nachbarn diese Information enthalten bzw. erfassen konnten höher als beispielsweise die benachbarten Subimages. Dies ist auch als der große Vorteil der Samplepoint Detection anzusehen.\\

\noindent
Weiterhin ließ sich während der Versuchsdurchführung deutlich erkennen, dass Bewegungen einen wesentlich Bestandteil der Hinderniserkennung darstellt. Wurden die Hindernisse bewegt, konnte gerade im Fall der Subimage Detection festgestellt werden, dass die Erkennung kleiner Hindernisse signifikant besser funktionierte wenn das Objekt Bewegung aufweist. Dadurch eliminieren sich bereits beschriebene Konfliktfälle in denen sich das zu erkennende Hindernis an der Kreuzung mehrerer Subimages befand. Die Bewegung sorgte in diesem Fall dafür das die Hindernisse in mehr Frames erkannt wurden als in einer statischen Szene. Selbiges Phänomen trat auch bei der Samplepoint Detection auf.\\

\noindent
Eine Veränderung der \emph{SGBM} Blockgröße hatte keine signifikanten Auswirkungen auf die Robustheit beider Algorithmen. Lediglich die bereits in Abschnitt \ref{sec:evaluation_Diskussion} erläuterten Ergebnisse bei 13 Pixeln brachte eine geringe Verbesserung der berechneten Distanz.\\

\noindent

% Auf eine genaue Positionierung jedes erkannten Hindernisses sowie eine Segmentierung nach erkannten Bereichen wurde bewusst verzichtet, da die berechneten dreidimensionalen Koordinaten als solche für eine weitere Hindernisvermeidung ausreichen.
% bisschen mehr statistik kram
% welcher ist wo signifikant besser
	% bezug auf hindernisgroesse
	% wahrscheinlichkeit das hindernis schlecht uz erkennen aber trotzdem wird es erkannt

% bei statischen szenen schlechtere erkennung, bewegung hilft jedoch hindernisse zu erkennen, da diese durch die in der evaluierung angesprochenen bereiche (kreuzungen, nicht betrachteter bereich) durchwanderen und somit eine erkennung auslösen.
 
% bewegung fundamental wichtig



