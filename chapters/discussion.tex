Im Rahmen des Kapitels \enquote{Evaluation} wurden beide entwickelten Methoden in verschiedenen Versuchen getestet. Die erlangten Ergebnisse beider Algorithmen unterscheiden sich in diversen Bereichen. Es erfolg somit eine Gegenüberstellung beider Algorithmen in Hinsicht auf die Robustheit der Erkennung sowie deren Performance.

% generell ist zu sagen das die mean besser funktioniert wenn die hindernisse nicht vor einem weit entfernten hintergrund platziert werden

% durch die geringen disparitäten der hinteren 'ebene' wirrd der median so weit verzerrt, dass kleine objekte einfach nicht mehr auffallen

% wenn hintergrund höhere disparitäten aufweist fallen hohe disparitäten auch mehr ins gewicht

% zum teil auch so bei der samplepoint detection, jedoch erwies sich diese in den tests als robuster

% gerade kleine Hindernisse wurden auf distanz besser erkannt

% trotzallem nicht immer eindeutig teilweise wurde ein Teil des objektes erkannt wie der stab aber nicht das eigentlich gesuchte objekt

% 

% ---------------------- section -----------------------
\section{Gegenüberstellung beider Algorithmen}
\label{sec:gegenueberstellung}

\subsection{Performance}
\label{subsec:discussion_performance}

Hinsichtlich der Performance der entwickelten Systeme wurden verschiednen Punkte betrachtet. Die zugrunde liegende Berechnung der Disparity Map ist der wohl wichtigste Faktor. Ist dieser Prozess langsam, so ist auch die Performance der Hinderniserkennung eingeschränkt. Weiterhin wird auch die Performance der einzelnen Methoden untersucht. Dabei werden folgende Situationen untersucht:
\begin{enumerate}
	\item Analyse der gesamten Schleife des Hauptprogramms
	\begin{enumerate}
		\item Hindernisse bewegen sich durch die Gefahrenzone
		\item der gesamte Sichtbereich ist mit einem Hindernis gefüllt
		\item es befindet sich kein Hindernis in der Gefahrenzone
	\end{enumerate}
	\item Analyse einzelner Erkennungssschritte
	\begin{enumerate}
		\item Geschwindigkeit der Update Funktion
		\item Geschwindigkeit der detectObstacles Funktion ohne Hindernisse
		\item Geschwindigkeit der detectObstacles Funktion mit einem Hindernis im gesamten Sichtbereich
	\end{enumerate}
\end{enumerate}

\noindent
Zu Beginn ist ein essenzieller Schritt die Geschwindigkeit der Disparity Map Berechnung zu analysieren. Dabei wurden beide Kameras im gebinnten Modus getestet. Die Aufnahmerate der Kameras beträgt dabei 50 Frames pro Sekunde bei einer Verschlusszeit von 10000 µs. Die unter Veränderung der Blockgröße erhaltenen Parameter sind in Tabelle \ref{tbl:disparity_framerate} dargestellt. Aus dieser ist zu erkennen, dass eine Modifikation dieses Parameters nur marginale Änderungen in der Geschwindigkeit auftreten. Die folgendenen gemessenen Werte sind die durchschnittliche Framerate aus 1000 Einzelbildern.

\begin{table}[h]
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	Block Größe & Zeit pro Frame & Frames pro Sekunde \\ \hline
	7           & 0.0412         & 24.21            \\ \hline
	9           & 0.0420         & 23.77            \\ \hline
	11          & 0.0413         & 24.17            \\ \hline
	13          & 0.0410         & 24.36            \\ \hline
	15          & 0.0412         & 24.22            \\ \hline
	21          & 0.0413         & 24.17            \\ \hline
	\end{tabular}
	\caption{Blockgröße und daraus resultierende Frameraten}
	\label{tbl:disparity_framerate}
\end{table}

\noindent
Die dabei gemessene Bildwiederholrate von 24 Einzelbildern pro Sekunde ist eine gute Voraussetzung für die Hinderniserkennung. Unter der Annahme das es zu keiner Verlangsamung dieser kommt ist es möglich sich mit Einer Geschwindigkeit von $12\frac{m}{s}$ zu bewegen und für jeden zurückgelegten Meter 2 berechnete Disparity Maps zu erhalten. Eine solche Geschwindigkeit ist bei besagter Framerate nicht die präferierte Geschwindigkeit jedoch potentiell möglich. Zudem in weiteren Schritten mehr Zeit für die Hinderniserkennung sowie die Entwicklung einer Vermeidungsstrategie in Betracht gezogen werden muss.\\

\noindent
Die Geschwindigkeit der eigentlichen Hinderniserkennung ist ebenfalls ein wesentlicher Faktor in der Betrachtung der gesamten Performance. Dazu wurden besaget Tests durchgeführt. Die daraus erhaltenen Ergebnisse für die Subimage Detection finden sich in Tabelle \ref{tbl:subimage_framerate}.

%TODO FIX VALUES
\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
Szenario & Zeit pro Frame (Detection) & Detection fps \\ \hline\hline
1(a)     & 0.0057                     & 173.35        \\ \hline
1(b)     & 0.0067                     & 147.69        \\ \hline
1(c)     & 0.0067                     & 147.69        \\ \hline\hline
2(a)     & 0.0021                     & 469.93        \\ \hline
2(b)     & 0.0001                     & 8759.63       \\ \hline
2(c)     & 0.0042                     & 234.64        \\ \hline
\end{tabular}
\caption{Gemessene Einzelbilder pro Sekunde sowie Gesamtframerate}
\label{tbl:subimage_framerate}
\end{table}

\noindent
Aus dieser wird ersichtlich, dass Szenario 1(a), welches einer echten Anwendung am nächsten kommt, bereits eine Framerate von 173 Einzelbildern pro Sekunde aufweist. Die darauf folgendenTests bestätigen die Annahme, dass keine wesentlich langsamere Framerate aufgrund der Hinderniserkennung zu erwarten ist. Im schlechtesten Fall, einem Hindernis welches den gesamtem Sichtbereich einnimmt ist die kombinierte Framerate nicht geringer als 20.96 wie die folgende Rechnung aufzeigt. Dabei entsprechen die genutzten Werte denen aus \ref{tbl:disparity_framerate} mit 13 Pixeln Blockgröße sowie \ref{tbl:subimage_framerate} 1(b). 

\begin{equation}
\label{eq:fps_calculation}
\begin{aligned}
	fps &= \frac{1}{t_{frame}}\\
	t_{frame} &= 0.0410 + 0.0067 = 0.0477\\
	fps &= \frac{1}{0.0477} = 20,96
\end{aligned}
\end{equation}

\noindent
Die somit verloren gegangenen Frames sorgen noch immer für eine schnelle Erkennung von Hindernissen. Die hohe Framerate in 2(b) resultiert aus der Funktionsweise der detectObstacles Funktion. Jene berechnet nur eine Pointcloud wenn die aktualisierten Werte innerhalb der Gefahrenzone liegen. Ohne vorhandene Hindernisse passiert somit nichts.\\

\noindent
Die nachfolgende Tabelle (\ref{tbl:samplepoint_framerate}) stellt die Ergebnisse des Versuches für die Samplepoint Detection dar. Auf den ersten Blick sind die erreichten Framerates (mit Ausnahme der Aktualisierung, sowie der Hinderniserkennung) generell niedriger als jene der Subimage Detection. 

%TODO FIX VALUES
\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
Szenario & Zeit pro Frame (Detection) & Detection fps \\ \hline\hline
1(a)     & 0.0074           			  & 133.61         \\ \hline
1(b)     & 0.0100           			  & 99.33          \\ \hline
1(c)     & 0.0016           			  & 606.84         \\ \hline\hline
2(a)     & 0.0015           			  & 647.07         \\ \hline
2(b)     & 0.0015           		  	  & 647.07         \\ \hline
2(c)     & 0.0083           	 		  & 120.33         \\ \hline
\end{tabular}
\caption{Gemessene Einzelbilder pro Sekunde sowie Gesamtframerate}
\label{tbl:samplepoint_framerate}
\end{table}

\noindent
Gerade die ermittelte Framerate in 1(b) gibt Anlass zu der Annahme, dass die Samplepoint Detection mehr Rechenleistung benötigt. Dies resultiert aus der Anzahl der zu betrachtenden Objekte. Im Vergleich zur Subimage Detection werden nicht nur 81 Bereiche betrachtet, sondern X. Auch im Echtwelt Szenario finden sich 30 Einzelbilder weniger pro Sekunde. Lediglich das Update sowie die Erkennung ohne Hindernisse erfolgt schneller. Die höhere Geschwindigkeit in der Aktualisierung resultiert aus der geringeren Anzahl an Pixeln welche betrachtet werden müssen. Nach der in \ref{eq:fps_calculation} erläuterten Rechnung ergibt sich bei der Samplepoint Detection eine durchschnittliche Framerate von $19,60$ Bildern/s.

% TODO INSERT NUM SAMPEOIUNTS HERE

   
% TODO resizing der initalbilder zur performance verbesserung

\subsection{Robustheit}
\label{subsec:discussion_robustness}
Wie die Evaluation bereits aufzeigt ist die Erkennung unterschiedlicher Hindernisgrößen als robust anzusehen. Beide Algorithmen erkennen sowohl große als auch kleine Hindernisse innerhalb der definierten Gefahrenzone. Die ermittelten Distanzen weisen zwar kleine Ungenauigkeiten auf, jedoch sind diese eher ein Resultat von Messungenauigkeiten sowie der verwendeten Bildgröße. Auch die dahingehend erstellten Punktwolken liefern genaue Positionsinformationen ausgehend von der aktuellen Weltposition der Drohne. Jene liegen im Rahmen dieser Arbeit nicht vor da dies als ein anderer Teil des SLAM Forschungsfeldes anzusehen ist.\\

% TODO Bilder pointcloud mean und sample desselben Objektes
\noindent
Bei der Erkennung kleiner Hindernisse ist jedoch zu erkennen, dass die entwickelte Samplepoint Detection wesentlich robustere Ergebnisse liefert als die Subimage Detection. Dies resultiert vornehmlich aus der signifikant kleineren Anzahl an Pixeln. Dadurch sind diese weniger empfänglich für Verzerrungen der berechneten Distanz wie Subimages. Enthält ein einziger Samplepoint zu wenige Daten um als Hindernis angesehen zu werden, so ist die Wahrscheinlichkeit das seine Nachbarn diese Information enthalten bzw. erfassen konnten höher als beispielsweise die benachbarten Subimages. Dies ist auch als der große Vorteil der Samplepoint Detection anzusehen.\\

\noindent
Weiterhin ließ sich während der Versuchsdurchführung deutlich erkennen, dass Bewegungen einen wesentlich Bestandteil der Hinderniserkennung darstellt. Wurden die Hindernisse bewegt, konnte gerade im Fall der Subimage Detection festgestellt werden, dass die Erkennung kleiner Hindernisse signifikant besser funktionierte wenn das Objekt Bewegung aufweist. Dadurch eliminieren sich bereits beschriebene Konfliktfälle in denen sich das zu erkennende Hindernis an der Kreuzung mehrerer Subimages befand. Die Bewegung sorgte in diesem Fall dafür das die Hindernisse in mehr Frames erkannt wurden als in einer statischen Szene. Selbiges Phänomen trat auch bei der Samplepoint Detection auf.\\

\noindent
Eine Veränderung der \emph{SGBM} Blockgröße hatte keine signifikanten Auswirkungen auf die Robustheit beider Algorithmen. Lediglich die bereits in Abschnitt \ref{sec:evaluation_Diskussion} erläuterten Ergebnisse bei 13 Pixeln brachte eine geringe Verbesserung der berechneten Distanz.\\

\noindent

% Auf eine genaue Positionierung jedes erkannten Hindernisses sowie eine Segmentierung nach erkannten Bereichen wurde bewusst verzichtet, da die berechneten dreidimensionalen Koordinaten als solche für eine weitere Hindernisvermeidung ausreichen.
% bisschen mehr statistik kram
% welcher ist wo signifikant besser
	% bezug auf hindernisgroesse
	% wahrscheinlichkeit das hindernis schlecht uz erkennen aber trotzdem wird es erkannt

% bei statischen szenen schlechtere erkennung, bewegung hilft jedoch hindernisse zu erkennen, da diese durch die in der evaluierung angesprochenen bereiche (kreuzungen, nicht betrachteter bereich) durchwanderen und somit eine erkennung auslösen.
 
% bewegung fundamental wichtig



